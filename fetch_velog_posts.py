from datetime import datetime, timedelta, timezone
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import time
import re
import os

# ë²¨ë¡œê·¸ ë¸”ë¡œê·¸ ì£¼ì†Œ
BLOG_URL = "https://velog.io/@mypalebluedot29"


def parse_relative_date(date_str, return_sort_key=False):
    """ ìƒëŒ€ì ì¸ ë‚ ì§œ (në¶„ ì „, nì‹œê°„ ì „, nì¼ ì „, ì–´ì œ)ì™€ ì ˆëŒ€ì ì¸ ë‚ ì§œ (YYYYë…„ Mì›” Dì¼)ë¥¼ ë³€í™˜ """
    now = datetime.now()

    # âœ… "YYYYë…„ Mì›” Dì¼" í˜•ì‹ ì²˜ë¦¬
    date_match = re.search(r"(\d{4})ë…„ (\d{1,2})ì›” (\d{1,2})ì¼", date_str)
    if date_match:
        year, month, day = date_match.groups()
        parsed_date = f"{year}-{month.zfill(2)}-{day.zfill(2)}"  # `YYYY-MM-DD` ë³€í™˜
        sort_key = int(f"{year}{month.zfill(2)}{day.zfill(2)}0000")  # ì •ë ¬ìš© í‚¤
        return (parsed_date, sort_key) if return_sort_key else parsed_date

    # âœ… "nì¼ ì „" ì²˜ë¦¬
    days_match = re.search(r"(\d+)ì¼ ì „", date_str)
    if days_match:
        days_ago = int(days_match.group(1))
        parsed_date = (now - timedelta(days=days_ago)).strftime("%Y-%m-%d")
        sort_key = int((now - timedelta(days=days_ago)).strftime("%Y%m%d%H%M"))
        return (parsed_date, sort_key) if return_sort_key else parsed_date

    # âœ… "nì‹œê°„ ì „" ì²˜ë¦¬
    hours_match = re.search(r"(\d+)ì‹œê°„ ì „", date_str)
    if hours_match:
        hours_ago = int(hours_match.group(1))
        adjusted_time = now - timedelta(hours=hours_ago)
        parsed_date = adjusted_time.strftime("%Y-%m-%d")  # ì˜¤ëŠ˜ì¸ì§€ ì–´ì œì¸ì§€ íŒë‹¨
        sort_key = int(adjusted_time.strftime("%Y%m%d%H%M"))
        return (parsed_date, sort_key) if return_sort_key else parsed_date

    # âœ… "në¶„ ì „" ì²˜ë¦¬
    minutes_match = re.search(r"(\d+)ë¶„ ì „", date_str)
    if minutes_match:
        minutes_ago = int(minutes_match.group(1))
        adjusted_time = now - timedelta(minutes=minutes_ago)
        parsed_date = adjusted_time.strftime("%Y-%m-%d")  # ì˜¤ëŠ˜ì¸ì§€ ì–´ì œì¸ì§€ íŒë‹¨
        sort_key = int(adjusted_time.strftime("%Y%m%d%H%M"))
        return (parsed_date, sort_key) if return_sort_key else parsed_date

    # âœ… "ì–´ì œ" ì²˜ë¦¬
    if "ì–´ì œ" in date_str:
        parsed_date = (now - timedelta(days=1)).strftime("%Y-%m-%d")
        sort_key = int((now - timedelta(days=1)).strftime("%Y%m%d%H%M"))
        return (parsed_date, sort_key) if return_sort_key else parsed_date

    # âœ… ê¸°ë³¸ê°’ (ì˜¤ëŠ˜ ë‚ ì§œ)
    parsed_date = now.strftime("%Y-%m-%d")
    sort_key = int(now.strftime("%Y%m%d%H%M"))
    return (parsed_date, sort_key) if return_sort_key else parsed_date


def fetch_recent_posts():
    """ ë²¨ë¡œê·¸ì—ì„œ ìµœì‹  ë¸”ë¡œê·¸ ê²Œì‹œë¬¼ì„ í¬ë¡¤ë§í•˜ì—¬ ë°˜í™˜ """
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    driver.get(BLOG_URL)
    time.sleep(5)
    driver.refresh()
    time.sleep(5)

    soup = BeautifulSoup(driver.page_source, "html.parser")
    driver.quit()

    post_elements = soup.select("div.FlatPostCard_block__a1qM7")
    posts = []

    for post in post_elements:
        a_tag = post.find("a", class_="VLink_block__Uwj4P")
        h2_tag = post.find("h2")
        date_spans = post.find_all("span") + post.find_all("p")

        if not a_tag or not h2_tag:
            continue

        title = h2_tag.text.strip()
        link = a_tag["href"]

        # âœ… ìƒëŒ€ URLì„ ì ˆëŒ€ URLë¡œ ë³€í™˜
        if not link.startswith("https://"):
            link = "https://velog.io" + link

        # âœ… ê¸°ë³¸ê°’ ì„¤ì • (ë‚ ì§œê°€ ì—†ì„ ê²½ìš° ëŒ€ë¹„)
        raw_date, sort_key = datetime.now().strftime("%Y-%m-%d"), int(datetime.now().strftime("%Y%m%d%H%M"))

        for element in date_spans:
            span_text = element.text.strip()
            if "ì „" in span_text or "ì–´ì œ" in span_text or re.search(r"\d{4}ë…„ \d{1,2}ì›” \d{1,2}ì¼", span_text):
                parsed_date, parsed_sort_key = parse_relative_date(span_text, return_sort_key=True)
                raw_date, sort_key = parsed_date, parsed_sort_key
                break

        print(f"âœ… ë³€í™˜ëœ ë‚ ì§œ: {raw_date}, ë§í¬: {link} ({title})")

        posts.append((title, raw_date, raw_date, link, sort_key))

    # âœ… ìµœì‹ ìˆœ ì •ë ¬
    posts.sort(key=lambda x: x[4], reverse=True)

    # âœ… í•­ìƒ 5ê°œ ìœ ì§€
    return posts[:5] if len(posts) >= 5 else posts


def update_readme(posts):
    """ README.md íŒŒì¼ì„ ì—…ë°ì´íŠ¸í•˜ì—¬ ìµœì‹  ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ë°˜ì˜ """
    try:
        with open("README.md", "r", encoding="utf-8") as f:
            content = f.readlines()

        try:
            start_index = content.index("<!-- BLOG-POST-LIST:START -->\n") + 1
            end_index = content.index("<!-- BLOG-POST-LIST:END -->\n")
        except ValueError:
            print("âš ï¸ README.mdì— ìë™ ì—…ë°ì´íŠ¸ ì˜ì—­ì´ ì—†ì–´ ìƒˆë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.")
            content.append("\n## ğŸ“ Latest Blog Posts\n")
            content.append("<!-- BLOG-POST-LIST:START -->\n")
            content.append("<!-- BLOG-POST-LIST:END -->\n")
            start_index = content.index("<!-- BLOG-POST-LIST:START -->\n") + 1
            end_index = content.index("<!-- BLOG-POST-LIST:END -->\n")

        # âœ… ìµœì‹  ë¸”ë¡œê·¸ ê¸€ì„ í‘œ í˜•ì‹ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        new_content = content[:start_index] + [
            "| ğŸ“ ì œëª© | ğŸ“… ì‘ì„±ì¼ | ğŸ”— ë§í¬ |\n",
            "|---------|------------------|---------|\n",
        ] + [
            f"| **{title}** | {converted_date} | [ë°”ë¡œê°€ê¸°]({link}) |\n"
            for title, _, converted_date, link, _ in posts
        ] + [
            "\nğŸ“… **Last Updated:** " + datetime.now(timezone(timedelta(hours=9))).strftime("%Y-%m-%d %H:%M:%S") + " (KST)\n",
            "ğŸ”— **[ğŸ“– ë” ë§ì€ ê¸€ ë³´ê¸°](https://velog.io/@mypalebluedot29)**\n"
        ] + content[end_index:]

        if "".join(content) != "".join(new_content):
            with open("README.md", "w", encoding="utf-8") as f:
                f.writelines(new_content)
            print("âœ… README.md ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
        else:
            print("â„¹ï¸ ë³€ê²½ ì‚¬í•­ì´ ì—†ì–´ ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŒ.")

    except Exception as e:
        print(f"âŒ README ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    recent_posts = fetch_recent_posts()
    if recent_posts:
        update_readme(recent_posts)
