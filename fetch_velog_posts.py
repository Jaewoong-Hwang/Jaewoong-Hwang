from datetime import datetime, timedelta, timezone
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import time
import re
import os

# ë²¨ë¡œê·¸ ë¸”ë¡œê·¸ ì£¼ì†Œ
BLOG_URL = "https://velog.io/@mypalebluedot29"

# âœ… ìƒëŒ€ ë‚ ì§œ ë³€í™˜ í•¨ìˆ˜
def parse_relative_date(date_str, return_sort_key=False):
    now = datetime.now()

    # âœ… "ì•½ 2ì‹œê°„ ì „" ê°™ì€ í‘œí˜„ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ
    numeric_value = re.sub(r"[^\d]", "", date_str)
    if not numeric_value.isdigit():
        return now.strftime("%Y-%m-%d %H:%M"), int(now.strftime("%Y%m%d%H%M"))

    numeric_value = int(numeric_value)

    if "ì´ˆ ì „" in date_str:
        result_date = now - timedelta(seconds=numeric_value)
        sort_key = 1000000 - numeric_value

    elif "ë¶„ ì „" in date_str:
        result_date = now - timedelta(minutes=numeric_value)
        sort_key = 900000 - numeric_value

    elif "ì‹œê°„ ì „" in date_str:
        result_date = now - timedelta(hours=numeric_value)
        sort_key = 800000 - numeric_value

    elif "ì–´ì œ" in date_str:
        result_date = now - timedelta(days=1)
        sort_key = 700000

    else:
        try:
            result_date = datetime.strptime(date_str, "%Y-%m-%d")
            sort_key = int(result_date.strftime("%Y%m%d"))
        except ValueError:
            return now.strftime("%Y-%m-%d %H:%M"), int(now.strftime("%Y%m%d%H%M"))

    formatted_date = result_date.strftime("%Y-%m-%d %H:%M")
    return (formatted_date, sort_key) if return_sort_key else formatted_date


# âœ… ë¸”ë¡œê·¸ í¬ë¡¤ë§ í•¨ìˆ˜
def fetch_recent_posts():
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    driver.get(BLOG_URL)
    time.sleep(5)
    driver.refresh()
    time.sleep(5)

    soup = BeautifulSoup(driver.page_source, "html.parser")
    driver.quit()

    post_elements = soup.select("div.FlatPostCard_block__a1qM7")
    posts = []

    for post in post_elements:
        a_tag = post.find("a", class_="VLink_block__Uwj4P")
        h2_tag = post.find("h2")
        date_spans = post.find_all("span") + post.find_all("p")

        if not a_tag or not h2_tag:
            continue

        title = h2_tag.text.strip()
        link = a_tag["href"]

        # âœ… ìƒëŒ€ URLì„ ì ˆëŒ€ URLë¡œ ë³€í™˜
        if not link.startswith("https://"):
            link = "https://velog.io" + link

        # âœ… ê¸°ë³¸ê°’ ì„¤ì • (ë‚ ì§œê°€ ì—†ì„ ê²½ìš° ëŒ€ë¹„)
        raw_date, sort_key = datetime.now().strftime("%Y-%m-%d %H:%M"), int(datetime.now().strftime("%Y%m%d%H%M"))

        for element in date_spans:
            span_text = element.text.strip()
            if "ì „" in span_text or "ì–´ì œ" in span_text or re.match(r"\d{4}-\d{2}-\d{2}", span_text):
                parsed_date = parse_relative_date(span_text, return_sort_key=True)
                if parsed_date:
                    raw_date, sort_key = parsed_date
                break

        print(f"âœ… ë³€í™˜ëœ ë‚ ì§œ: {raw_date}, ë§í¬: {link} ({title})")

        posts.append((title, raw_date, raw_date, link, sort_key))

    # âœ… ìµœì‹ ìˆœ ì •ë ¬ (ì´ˆ â†’ ë¶„ â†’ ì‹œê°„ â†’ ì–´ì œ â†’ ë‚ ì§œ)
    posts.sort(key=lambda x: x[4], reverse=True)

    # âœ… í•­ìƒ 5ê°œ ìœ ì§€
    return posts[:5] if len(posts) >= 5 else posts


# âœ… README ì—…ë°ì´íŠ¸ í•¨ìˆ˜
def update_readme(posts):
    try:
        # âœ… README.md íŒŒì¼ì´ ì—†ì„ ê²½ìš° ìƒì„±
        if not os.path.exists("README.md"):
            print("âš ï¸ README.md íŒŒì¼ì´ ì—†ì–´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            with open("README.md", "w", encoding="utf-8") as f:
                f.write("# ğŸ“Œ My GitHub Profile\n\n")

        with open("README.md", "r", encoding="utf-8") as f:
            content = f.readlines()

        try:
            start_index = content.index("<!-- BLOG-POST-LIST:START -->\n") + 1
            end_index = content.index("<!-- BLOG-POST-LIST:END -->\n")
        except ValueError:
            print("âš ï¸ README.mdì— ìë™ ì—…ë°ì´íŠ¸ ì˜ì—­ì´ ì—†ì–´ ìƒˆë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.")
            content.append("\n## ğŸ“ Latest Blog Posts\n")
            content.append("<!-- BLOG-POST-LIST:START -->\n")
            content.append("<!-- BLOG-POST-LIST:END -->\n")
            start_index = content.index("<!-- BLOG-POST-LIST:START -->\n") + 1
            end_index = content.index("<!-- BLOG-POST-LIST:END -->\n")

        new_content = content[:start_index] + [
            "| ğŸ“ ì œëª© | ğŸ“… ì‘ì„±ì¼ (ìƒëŒ€/ë³€í™˜) | ğŸ”— ë§í¬ |\n",
            "|---------|------------------|---------|\n",
        ] + [
            f"| **{title}** | {original_date} ({converted_date}) | [ë°”ë¡œê°€ê¸°]({link}) |\n"
            if original_date != converted_date else f"| **{title}** | {converted_date} | [ë°”ë¡œê°€ê¸°]({link}) |\n"
            for title, original_date, converted_date, link, _ in posts
        ] + [
            "\nğŸ“… **Last Updated:** " + datetime.now(timezone(timedelta(hours=9))).strftime("%Y-%m-%d %H:%M:%S") + " (KST)\n",
            "ğŸ”— **[ğŸ“– ë” ë§ì€ ê¸€ ë³´ê¸°](https://velog.io/@mypalebluedot29)**\n"
        ] + content[end_index:]

        if "".join(content) != "".join(new_content):
            with open("README.md", "w", encoding="utf-8") as f:
                f.writelines(new_content)
            print("âœ… README.md ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
        else:
            print("â„¹ï¸ ë³€ê²½ ì‚¬í•­ì´ ì—†ì–´ ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŒ.")

    except Exception as e:
        print(f"âŒ README ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    recent_posts = fetch_recent_posts()
    if recent_posts:
        update_readme(recent_posts)
