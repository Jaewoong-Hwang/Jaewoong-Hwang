from datetime import datetime, timedelta, timezone
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import time
import re
import os

# ë²¨ë¡œê·¸ ë¸”ë¡œê·¸ ì£¼ì†Œ
BLOG_URL = "https://velog.io/@mypalebluedot29"

def parse_relative_date(date_str, return_sort_key=False, for_readme=False):
    """ ìƒëŒ€ì ì¸ ë‚ ì§œ(ì˜ˆ: '11ë¶„ ì „', 'ì–´ì œ')ë¥¼ ë³€í™˜í•˜ì—¬ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ """
    now = datetime.now()

    if "ë¶„ ì „" in date_str or "ì‹œê°„ ì „" in date_str:
        result_date = now.strftime("%Y-%m-%d")  # ì˜¤ëŠ˜ ë‚ ì§œë¡œ ë³€í™˜
        sort_key = int(now.strftime("%Y%m%d%H%M"))  # ìµœì‹ ìˆœ ì •ë ¬ í‚¤

    elif "ì–´ì œ" in date_str:
        result_date = (now - timedelta(days=1)).strftime("%Y-%m-%d")  
        sort_key = int((now - timedelta(days=1)).strftime("%Y%m%d%H%M"))  

    else:
        try:
            result_date = datetime.strptime(date_str, "%Y-%m-%d").strftime("%Y-%m-%d")
            sort_key = int(datetime.strptime(date_str, "%Y-%m-%d").strftime("%Y%m%d%H%M"))
        except ValueError:
            result_date = now.strftime("%Y-%m-%d")
            sort_key = int(now.strftime("%Y%m%d%H%M"))

    return (result_date, sort_key) if return_sort_key else result_date


def fetch_recent_posts():
    """ ë²¨ë¡œê·¸ì—ì„œ ìµœì‹  ë¸”ë¡œê·¸ ê²Œì‹œë¬¼ì„ í¬ë¡¤ë§í•˜ì—¬ ë°˜í™˜ """
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    driver.get(BLOG_URL)
    time.sleep(5)
    driver.refresh()
    time.sleep(5)

    soup = BeautifulSoup(driver.page_source, "html.parser")
    driver.quit()

    post_elements = soup.select("div.FlatPostCard_block__a1qM7")
    posts = []

    for post in post_elements:
        a_tag = post.find("a", class_="VLink_block__Uwj4P")
        h2_tag = post.find("h2")
        date_spans = post.find_all("span") + post.find_all("p")

        if not a_tag or not h2_tag:
            continue

        title = h2_tag.text.strip()
        link = a_tag["href"]

        # âœ… ìƒëŒ€ URLì„ ì ˆëŒ€ URLë¡œ ë³€í™˜
        if not link.startswith("https://"):
            link = "https://velog.io" + link

        # âœ… ê¸°ë³¸ê°’ ì„¤ì • (ë‚ ì§œê°€ ì—†ì„ ê²½ìš° ëŒ€ë¹„)
        raw_date, sort_key = datetime.now().strftime("%Y-%m-%d %H:%M"), int(datetime.now().strftime("%Y%m%d%H%M"))

        for element in date_spans:
            span_text = element.text.strip()
            if "ì „" in span_text or "ì–´ì œ" in span_text or re.match(r"\d{4}-\d{2}-\d{2}", span_text):
                parsed_date = parse_relative_date(span_text, return_sort_key=True)
                if parsed_date:
                    raw_date, sort_key = parsed_date
                break

        print(f"âœ… ë³€í™˜ëœ ë‚ ì§œ: {raw_date}, ë§í¬: {link} ({title})")

        # âœ… ë¦¬ë“œë¯¸ ì—…ë°ì´íŠ¸ìš© ì˜¤ëŠ˜ ë‚ ì§œ ë³€í™˜ (for_readme=True ì¶”ê°€)
        readme_date = parse_relative_date(raw_date, for_readme=True)

        posts.append((title, raw_date, readme_date, link, sort_key))

    # âœ… ìµœì‹ ìˆœ ì •ë ¬ (ì´ˆ â†’ ë¶„ â†’ ì‹œê°„ â†’ ì–´ì œ â†’ ë‚ ì§œ)
    posts.sort(key=lambda x: x[4], reverse=True)

    # âœ… í•­ìƒ 5ê°œ ìœ ì§€
    return posts[:5] if len(posts) >= 5 else posts


def update_readme(posts):
    """ README.md íŒŒì¼ì„ ì—…ë°ì´íŠ¸í•˜ì—¬ ìµœì‹  ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ë°˜ì˜ """
    try:
        with open("README.md", "r", encoding="utf-8") as f:
            content = f.readlines()

        try:
            start_index = content.index("<!-- BLOG-POST-LIST:START -->\n") + 1
            end_index = content.index("<!-- BLOG-POST-LIST:END -->\n")
        except ValueError:
            print("âš ï¸ README.mdì— ìë™ ì—…ë°ì´íŠ¸ ì˜ì—­ì´ ì—†ì–´ ìƒˆë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.")
            content.append("\n## ğŸ“ Latest Blog Posts\n")
            content.append("<!-- BLOG-POST-LIST:START -->\n")
            content.append("<!-- BLOG-POST-LIST:END -->\n")
            start_index = content.index("<!-- BLOG-POST-LIST:START -->\n") + 1
            end_index = content.index("<!-- BLOG-POST-LIST:END -->\n")

        # âœ… ìµœì‹  ë¸”ë¡œê·¸ ê¸€ì„ í‘œ í˜•ì‹ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        new_content = content[:start_index] + [
            "| ğŸ“ ì œëª© | ğŸ“… ì‘ì„±ì¼ (ìƒëŒ€/ë³€í™˜) | ğŸ”— ë§í¬ |\n",
            "|---------|------------------|---------|\n",
        ] + [
            f"| **{title}** | {original_date} ({readme_date}) | [ë°”ë¡œê°€ê¸°]({link}) |\n"
            if original_date != readme_date else f"| **{title}** | {readme_date} | [ë°”ë¡œê°€ê¸°]({link}) |\n"
            for title, original_date, readme_date, link, _ in posts
        ] + [
            "\nğŸ“… **Last Updated:** " + datetime.now(timezone(timedelta(hours=9))).strftime("%Y-%m-%d %H:%M:%S") + " (KST)\n",
            "ğŸ”— **[ğŸ“– ë” ë§ì€ ê¸€ ë³´ê¸°](https://velog.io/@mypalebluedot29)**\n"
        ] + content[end_index:]

        if "".join(content) != "".join(new_content):
            with open("README.md", "w", encoding="utf-8") as f:
                f.writelines(new_content)
            print("âœ… README.md ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
        else:
            print("â„¹ï¸ ë³€ê²½ ì‚¬í•­ì´ ì—†ì–´ ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŒ.")

    except Exception as e:
        print(f"âŒ README ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    recent_posts = fetch_recent_posts()
    if recent_posts:
        update_readme(recent_posts)
